{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: BERT, ELMo, and Flair Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:45:12,312 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpjmflv7jx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19689779/19689779 [00:02<00:00, 6776429.21B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:45:15,700 copying /tmp/tmpjmflv7jx to cache at /home/wohlg/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
      "2019-04-20 17:45:15,752 removing temp file /tmp/tmpjmflv7jx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"The grass is green .\" - 5 Tokens]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "flair_embedding_forward = FlairEmbeddings('news-forward-fast')\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "flair_embedding_forward.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:46:20,542 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpinexn57n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034575/73034575 [00:27<00:00, 2698079.11B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:46:48,036 copying /tmp/tmpinexn57n to cache at /home/wohlg/.flair/embeddings/news-backward-0.4.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:46:48,215 removing temp file /tmp/tmpinexn57n\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "\n",
    "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
    "stacked_embeddings = StackedEmbeddings([\n",
    "                                        WordEmbeddings('glove'), \n",
    "                                        FlairEmbeddings('news-forward'), \n",
    "                                        FlairEmbeddings('news-backward'),\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from docs: Words are now embedded using a concatenation of three different embeddings. This combination often gives state-of-the-art accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "tensor([-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -4.4014e-04,\n",
      "        -3.9301e-02,  1.0601e-02])\n",
      "vector size 4196 dim\n",
      "Token: 2 grass\n",
      "tensor([-8.1353e-01,  9.4042e-01, -2.4048e-01,  ..., -3.7749e-04,\n",
      "        -2.3563e-02,  1.1700e-02])\n",
      "vector size 4196 dim\n",
      "Token: 3 is\n",
      "tensor([-0.5426,  0.4148,  1.0322,  ..., -0.0061,  0.0112,  0.0100])\n",
      "vector size 4196 dim\n",
      "Token: 4 green\n",
      "tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0026, -0.0118,  0.0455])\n",
      "vector size 4196 dim\n",
      "Token: 5 .\n",
      "tensor([-3.3979e-01,  2.0941e-01,  4.6348e-01,  ..., -2.3405e-04,\n",
      "         3.8688e-03,  5.7725e-03])\n",
      "vector size 4196 dim\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# just embed a sentence using the StackedEmbedding as you would with any single embedding.\n",
    "stacked_embeddings.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)\n",
    "    print('vector size', len(token.embedding), 'dim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:01<00:00, 127489.91B/s]\n",
      "100%|██████████| 407873900/407873900 [01:21<00:00, 4991434.02B/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"The grass is green .\" - 5 Tokens]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import BertEmbeddings\n",
    "\n",
    "# init embedding\n",
    "embedding = BertEmbeddings()\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ELMO embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "# init embedding\n",
    "embedding = ELMoEmbeddings()\n",
    "\n",
    "# create a sentence\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# embed words in sentence\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:51:51,505 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/lm-multi-forward-v0.1.pt not found in cache, downloading to /tmp/tmp8t6k_y2e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034300/73034300 [00:11<00:00, 6546661.72B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:52:03,180 copying /tmp/tmp8t6k_y2e to cache at /home/wohlg/.flair/embeddings/lm-multi-forward-v0.1.pt\n",
      "2019-04-20 17:52:03,366 removing temp file /tmp/tmp8t6k_y2e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:52:03,963 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/lm-multi-backward-v0.1.pt not found in cache, downloading to /tmp/tmp54f3dvhh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034304/73034304 [00:08<00:00, 8230609.67B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:52:13,546 copying /tmp/tmp54f3dvhh to cache at /home/wohlg/.flair/embeddings/lm-multi-backward-v0.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-20 17:52:13,714 removing temp file /tmp/tmp54f3dvhh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 995526/995526 [00:00<00:00, 1079012.74B/s]\n",
      "100%|██████████| 662804195/662804195 [01:51<00:00, 5930243.10B/s] \n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings, BertEmbeddings\n",
    "\n",
    "# init Flair embeddings\n",
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
    "\n",
    "# init multilingual BERT\n",
    "bert_embedding = BertEmbeddings('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import StackedEmbeddings\n",
    "\n",
    "# now create the StackedEmbedding object that combines all embeddings\n",
    "stacked_embeddings = StackedEmbeddings(\n",
    "    embeddings=[flair_forward_embedding, flair_backward_embedding, bert_embedding])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "tensor([-1.4812e-07,  4.5007e-08,  6.0273e-07,  ...,  3.1089e-01,\n",
      "         7.5928e-01,  1.8466e-01])\n",
      "vector size 7168 dim\n",
      "Token: 2 grass\n",
      "tensor([ 1.6254e-04,  1.8764e-07, -7.9041e-09,  ...,  7.1181e-01,\n",
      "         1.3930e-01,  2.0155e-01])\n",
      "vector size 7168 dim\n",
      "Token: 3 is\n",
      "tensor([-2.4521e-04,  3.4869e-07,  5.5841e-06,  ..., -2.5609e-01,\n",
      "         9.6020e-01, -2.7864e-01])\n",
      "vector size 7168 dim\n",
      "Token: 4 green\n",
      "tensor([8.3005e-05, 4.7261e-08, 5.7315e-07,  ..., 8.8403e-01, 9.8659e-01,\n",
      "        5.5930e-02])\n",
      "vector size 7168 dim\n",
      "Token: 5 .\n",
      "tensor([-8.3244e-07,  1.6451e-07, -1.7201e-08,  ..., -5.5942e-01,\n",
      "         8.2404e-01,  7.4348e-02])\n",
      "vector size 7168 dim\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# just embed a sentence using the StackedEmbedding as you would with any single embedding.\n",
    "stacked_embeddings.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)\n",
    "    print('vector size', len(token.embedding), 'dim')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
