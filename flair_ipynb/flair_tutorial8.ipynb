{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8: Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-29 20:04:31,049 Reading data from /home/wohlg/itmo/teaching/nlp/flair/testcorpus\n",
      "2019-04-29 20:04:31,062 Train: /home/wohlg/itmo/teaching/nlp/flair/testcorpus/train.txt\n",
      "2019-04-29 20:04:31,063 Dev: /home/wohlg/itmo/teaching/nlp/flair/testcorpus/dev.txt\n",
      "2019-04-29 20:04:31,064 Test: /home/wohlg/itmo/teaching/nlp/flair/testcorpus/test.txt\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from pathlib import Path\n",
    "\n",
    "# use your own data path\n",
    "data_folder = Path('/home/wohlg/itmo/teaching/nlp/flair/testcorpus')\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_classification_corpus(data_folder,\n",
    "                                                                     test_file='test.txt',\n",
    "                                                                     dev_file='dev.txt',\n",
    "                                                                     train_file='train.txt').downsample(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedCorpus: 800 train + 100 dev + 101 test sentences\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wohlg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated method __init__. (Use 'FlairEmbeddings' instead.) -- Deprecated since version 0.4.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/wohlg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated method __init__. (Use 'FlairEmbeddings' instead.) -- Deprecated since version 0.4.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "from flair.hyperparameter.param_selection import SearchSpace, Parameter\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, CharLMEmbeddings\n",
    "\n",
    "\n",
    "# define your search space\n",
    "search_space = SearchSpace()\n",
    "search_space.add(Parameter.EMBEDDINGS, hp.choice, options=[\n",
    "    [ WordEmbeddings('en') ], \n",
    "    [ CharLMEmbeddings('news-forward'), CharLMEmbeddings('news-backward') ]\n",
    "])\n",
    "search_space.add(Parameter.HIDDEN_SIZE, hp.choice, options=[32, 64, 128])\n",
    "search_space.add(Parameter.RNN_LAYERS, hp.choice, options=[1, 2])\n",
    "search_space.add(Parameter.DROPOUT, hp.uniform, low=0.0, high=0.5)\n",
    "search_space.add(Parameter.LEARNING_RATE, hp.choice, options=[0.05, 0.1, 0.15, 0.2])\n",
    "search_space.add(Parameter.MINI_BATCH_SIZE, hp.choice, options=[8, 16, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-29 20:07:31,761 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:07:31,762 Evaluation run: 1\n",
      "2019-04-29 20:07:31,765 Evaluating parameter combination:\n",
      "2019-04-29 20:07:31,766 \tdropout: 0.47078441765795953\n",
      "2019-04-29 20:07:31,772 \tembeddings: /home/wohlg/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-04-29 20:07:31,774 \thidden_size: 128\n",
      "2019-04-29 20:07:31,778 \tlearning_rate: 0.1\n",
      "2019-04-29 20:07:31,779 \tmini_batch_size: 8\n",
      "2019-04-29 20:07:31,779 \trnn_layers: 1\n",
      "2019-04-29 20:07:31,780 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:07:31,828 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:07:31,830 Training run: 1\n",
      "2019-04-29 20:07:31,838 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:07:31,840 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-29 20:07:31,842 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:07:32,173 epoch 1 - iter 0/100 - loss 0.08738849\n",
      "2019-04-29 20:07:33,805 epoch 1 - iter 10/100 - loss 0.09018114\n",
      "2019-04-29 20:07:36,176 epoch 1 - iter 20/100 - loss 0.09131287\n",
      "2019-04-29 20:07:37,528 epoch 1 - iter 30/100 - loss 0.09135429\n",
      "2019-04-29 20:07:39,131 epoch 1 - iter 40/100 - loss 0.09117079\n",
      "2019-04-29 20:07:40,898 epoch 1 - iter 50/100 - loss 0.08965393\n",
      "2019-04-29 20:07:42,508 epoch 1 - iter 60/100 - loss 0.08988022\n",
      "2019-04-29 20:07:44,001 epoch 1 - iter 70/100 - loss 0.08946451\n",
      "2019-04-29 20:07:45,431 epoch 1 - iter 80/100 - loss 0.08920464\n",
      "2019-04-29 20:07:46,986 epoch 1 - iter 90/100 - loss 0.08903345\n",
      "2019-04-29 20:07:48,149 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:07:48,152 EPOCH 1 done: loss 0.0895 - lr 0.1000 - bad epochs 0\n",
      "2019-04-29 20:07:48,566 DEV  : loss 0.08973813 - f-score 0.5000 - acc 0.3333\n",
      "2019-04-29 20:07:48,567 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:07:48,879 epoch 2 - iter 0/100 - loss 0.09112416\n",
      "2019-04-29 20:07:50,442 epoch 2 - iter 10/100 - loss 0.08906551\n",
      "2019-04-29 20:07:52,093 epoch 2 - iter 20/100 - loss 0.08937821\n",
      "2019-04-29 20:07:53,632 epoch 2 - iter 30/100 - loss 0.08988098\n",
      "2019-04-29 20:07:55,106 epoch 2 - iter 40/100 - loss 0.08795266\n",
      "2019-04-29 20:07:56,683 epoch 2 - iter 50/100 - loss 0.08832704\n",
      "2019-04-29 20:07:59,167 epoch 2 - iter 60/100 - loss 0.08798460\n",
      "2019-04-29 20:08:01,350 epoch 2 - iter 70/100 - loss 0.08810977\n",
      "2019-04-29 20:08:03,755 epoch 2 - iter 80/100 - loss 0.08799709\n",
      "2019-04-29 20:08:06,268 epoch 2 - iter 90/100 - loss 0.08790093\n",
      "2019-04-29 20:08:08,759 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:08,761 EPOCH 2 done: loss 0.0877 - lr 0.1000 - bad epochs 0\n",
      "2019-04-29 20:08:09,433 DEV  : loss 0.08869173 - f-score 0.5500 - acc 0.3793\n",
      "2019-04-29 20:08:09,436 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:09,438 Testing using best model ...\n",
      "2019-04-29 20:08:10,305 MICRO_AVG: acc 0.3931 - f1-score 0.5644\n",
      "2019-04-29 20:08:10,306 MACRO_AVG: acc 0.2822 - f1-score 0.3608\n",
      "2019-04-29 20:08:10,308 1          tp: 0 - fp: 0 - fn: 44 - tn: 57 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-29 20:08:10,311 2          tp: 57 - fp: 44 - fn: 0 - tn: 0 - precision: 0.5644 - recall: 1.0000 - accuracy: 0.5644 - f1-score: 0.7216\n",
      "2019-04-29 20:08:10,314 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:10,325 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:10,335 Training run: 2\n",
      "2019-04-29 20:08:10,344 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:10,347 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-29 20:08:10,351 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:10,615 epoch 1 - iter 0/100 - loss 0.08570326\n",
      "2019-04-29 20:08:12,958 epoch 1 - iter 10/100 - loss 0.09353253\n",
      "2019-04-29 20:08:14,693 epoch 1 - iter 20/100 - loss 0.09195335\n",
      "2019-04-29 20:08:17,051 epoch 1 - iter 30/100 - loss 0.09205236\n",
      "2019-04-29 20:08:19,436 epoch 1 - iter 40/100 - loss 0.09152552\n",
      "2019-04-29 20:08:21,844 epoch 1 - iter 50/100 - loss 0.09044866\n",
      "2019-04-29 20:08:23,982 epoch 1 - iter 60/100 - loss 0.09099115\n",
      "2019-04-29 20:08:26,042 epoch 1 - iter 70/100 - loss 0.09095717\n",
      "2019-04-29 20:08:27,735 epoch 1 - iter 80/100 - loss 0.09061259\n",
      "2019-04-29 20:08:29,569 epoch 1 - iter 90/100 - loss 0.09010403\n",
      "2019-04-29 20:08:30,625 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:30,626 EPOCH 1 done: loss 0.0900 - lr 0.1000 - bad epochs 0\n",
      "2019-04-29 20:08:30,969 DEV  : loss 0.08979671 - f-score 0.5100 - acc 0.3423\n",
      "2019-04-29 20:08:30,970 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:31,138 epoch 2 - iter 0/100 - loss 0.08128807\n",
      "2019-04-29 20:08:32,459 epoch 2 - iter 10/100 - loss 0.08569844\n",
      "2019-04-29 20:08:33,860 epoch 2 - iter 20/100 - loss 0.08811708\n",
      "2019-04-29 20:08:36,202 epoch 2 - iter 30/100 - loss 0.08843161\n",
      "2019-04-29 20:08:37,628 epoch 2 - iter 40/100 - loss 0.08861781\n",
      "2019-04-29 20:08:39,134 epoch 2 - iter 50/100 - loss 0.08834129\n",
      "2019-04-29 20:08:40,939 epoch 2 - iter 60/100 - loss 0.08831130\n",
      "2019-04-29 20:08:42,917 epoch 2 - iter 70/100 - loss 0.08838621\n",
      "2019-04-29 20:08:44,871 epoch 2 - iter 80/100 - loss 0.08814196\n",
      "2019-04-29 20:08:46,570 epoch 2 - iter 90/100 - loss 0.08805192\n",
      "2019-04-29 20:08:48,199 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:48,202 EPOCH 2 done: loss 0.0877 - lr 0.1000 - bad epochs 0\n",
      "2019-04-29 20:08:48,589 DEV  : loss 0.08910420 - f-score 0.5500 - acc 0.3793\n",
      "2019-04-29 20:08:48,590 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:48,591 Testing using best model ...\n",
      "2019-04-29 20:08:48,953 MICRO_AVG: acc 0.3931 - f1-score 0.5644\n",
      "2019-04-29 20:08:48,954 MACRO_AVG: acc 0.2822 - f1-score 0.3608\n",
      "2019-04-29 20:08:48,955 1          tp: 0 - fp: 0 - fn: 44 - tn: 57 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-29 20:08:48,956 2          tp: 57 - fp: 44 - fn: 0 - tn: 0 - precision: 0.5644 - recall: 1.0000 - accuracy: 0.5644 - f1-score: 0.7216\n",
      "2019-04-29 20:08:48,956 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:48,962 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:48,963 Training run: 3\n",
      "2019-04-29 20:08:48,967 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:48,968 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-29 20:08:48,969 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:08:49,240 epoch 1 - iter 0/100 - loss 0.09375609\n",
      "2019-04-29 20:08:51,117 epoch 1 - iter 10/100 - loss 0.09455697\n",
      "2019-04-29 20:08:53,077 epoch 1 - iter 20/100 - loss 0.09263379\n",
      "2019-04-29 20:08:54,866 epoch 1 - iter 30/100 - loss 0.09170124\n",
      "2019-04-29 20:08:56,745 epoch 1 - iter 40/100 - loss 0.09109682\n",
      "2019-04-29 20:08:59,459 epoch 1 - iter 50/100 - loss 0.09218904\n",
      "2019-04-29 20:09:01,411 epoch 1 - iter 60/100 - loss 0.09154010\n",
      "2019-04-29 20:09:02,816 epoch 1 - iter 70/100 - loss 0.09134039\n",
      "2019-04-29 20:09:04,869 epoch 1 - iter 80/100 - loss 0.09112774\n",
      "2019-04-29 20:09:06,984 epoch 1 - iter 90/100 - loss 0.09108517\n",
      "2019-04-29 20:09:08,841 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-29 20:09:08,846 EPOCH 1 done: loss 0.0909 - lr 0.1000 - bad epochs 0\n",
      "2019-04-29 20:09:09,347 DEV  : loss 0.08911197 - f-score 0.6300 - acc 0.4599\n",
      "2019-04-29 20:09:09,348 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:09,444 epoch 2 - iter 0/100 - loss 0.09045847\n",
      "2019-04-29 20:09:11,066 epoch 2 - iter 10/100 - loss 0.08689481\n",
      "2019-04-29 20:09:12,950 epoch 2 - iter 20/100 - loss 0.08756529\n",
      "2019-04-29 20:09:14,614 epoch 2 - iter 30/100 - loss 0.08808527\n",
      "2019-04-29 20:09:15,957 epoch 2 - iter 40/100 - loss 0.08899501\n",
      "2019-04-29 20:09:17,596 epoch 2 - iter 50/100 - loss 0.08895745\n",
      "2019-04-29 20:09:19,366 epoch 2 - iter 60/100 - loss 0.08903889\n",
      "2019-04-29 20:09:20,949 epoch 2 - iter 70/100 - loss 0.08879535\n",
      "2019-04-29 20:09:22,739 epoch 2 - iter 80/100 - loss 0.08902576\n",
      "2019-04-29 20:09:24,330 epoch 2 - iter 90/100 - loss 0.08865670\n",
      "2019-04-29 20:09:25,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:25,552 EPOCH 2 done: loss 0.0886 - lr 0.1000 - bad epochs 0\n",
      "2019-04-29 20:09:25,876 DEV  : loss 0.08860418 - f-score 0.5500 - acc 0.3793\n",
      "2019-04-29 20:09:25,878 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:25,878 Testing using best model ...\n",
      "2019-04-29 20:09:26,259 MICRO_AVG: acc 0.3931 - f1-score 0.5644\n",
      "2019-04-29 20:09:26,262 MACRO_AVG: acc 0.2822 - f1-score 0.3608\n",
      "2019-04-29 20:09:26,263 1          tp: 0 - fp: 0 - fn: 44 - tn: 57 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
      "2019-04-29 20:09:26,263 2          tp: 57 - fp: 44 - fn: 0 - tn: 0 - precision: 0.5644 - recall: 1.0000 - accuracy: 0.5644 - f1-score: 0.7216\n",
      "2019-04-29 20:09:26,265 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:26,268 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:26,270 Done evaluating parameter combination:\n",
      "2019-04-29 20:09:26,270 \tdropout: 0.47078441765795953\n",
      "2019-04-29 20:09:26,271 \tembeddings: /home/wohlg/.flair/embeddings/en-fasttext-news-300d-1M\n",
      "2019-04-29 20:09:26,273 \thidden_size: 128\n",
      "2019-04-29 20:09:26,273 \tlearning_rate: 0.1\n",
      "2019-04-29 20:09:26,275 \tmini_batch_size: 8\n",
      "2019-04-29 20:09:26,277 \trnn_layers: 1\n",
      "2019-04-29 20:09:26,278 score: 0.45166666666666666\n",
      "2019-04-29 20:09:26,279 variance: 0.000875\n",
      "2019-04-29 20:09:26,279 test_score: 0.5644\n",
      "\n",
      "2019-04-29 20:09:26,281 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:26,287 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:26,288 Evaluation run: 2\n",
      "2019-04-29 20:09:26,289 Evaluating parameter combination:\n",
      "2019-04-29 20:09:26,290 \tdropout: 0.12148578059515736\n",
      "2019-04-29 20:09:26,291 \tembeddings: /home/wohlg/.flair/embeddings/lm-news-english-forward-v0.2rc.pt,/home/wohlg/.flair/embeddings/lm-news-english-backward-v0.2rc.pt\n",
      "2019-04-29 20:09:26,292 \thidden_size: 128\n",
      "2019-04-29 20:09:26,292 \tlearning_rate: 0.1\n",
      "2019-04-29 20:09:26,293 \tmini_batch_size: 8\n",
      "2019-04-29 20:09:26,294 \trnn_layers: 1\n",
      "2019-04-29 20:09:26,295 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:26,479 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:26,481 Training run: 1\n",
      "2019-04-29 20:09:26,700 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:26,701 Evaluation method: MICRO_F1_SCORE\n",
      "2019-04-29 20:09:26,702 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:09:51,535 epoch 1 - iter 0/100 - loss 0.08737132\n",
      "2019-04-29 20:14:02,858 epoch 1 - iter 10/100 - loss 0.17745346\n",
      "2019-04-29 20:14:58,939 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:14:58,941 Exiting from training early.\n",
      "2019-04-29 20:14:58,954 ----------------------------------------------------------------------------------------------------\n",
      "2019-04-29 20:14:58,956 Testing using best model ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5b31870c84a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# start the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mparam_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/hyperparameter/param_selection.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, space, max_evals)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSearchSpace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0msearch_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mlog_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[1;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[1;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/hyperparameter/param_selection.py\u001b[0m in \u001b[0;36m_objective\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                    \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                    \u001b[0mparam_selection_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                    **training_params)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# take the average over the last three scores of training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, base_path, evaluation_metric, learning_rate, mini_batch_size, eval_mini_batch_size, max_epochs, anneal_factor, patience, anneal_against_train_loss, train_with_dev, monitor_train, embeddings_in_memory, checkpoint, save_final_model, anneal_with_restarts, test_mode, param_selection_mode, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# test best model if test data is present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mfinal_test\u001b[0;34m(self, base_path, embeddings_in_memory, evaluation_metric, eval_mini_batch_size)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         test_metric, test_loss = self.evaluate(self.model, self.corpus.test, eval_mini_batch_size=eval_mini_batch_size,\n\u001b[0;32m--> 278\u001b[0;31m                                                embeddings_in_memory=embeddings_in_memory)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'MICRO_AVG: acc {test_metric.micro_avg_accuracy()} - f1-score {test_metric.micro_avg_f_score()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_set, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             return ModelTrainer._evaluate_text_classifier(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n\u001b[0;32m--> 343\u001b[0;31m                                                           out_path)\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             return ModelTrainer._evaluate_sequence_tagger(model, data_set, eval_mini_batch_size, embeddings_in_memory,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/trainers/trainer.py\u001b[0m in \u001b[0;36m_evaluate_text_classifier\u001b[0;34m(model, sentences, eval_mini_batch_size, embeddings_in_memory, out_path)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mclear_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malso_clear_word_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0membeddings_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward_labels_and_loss\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_labels_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obtain_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtext_embedding_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;31m# first, sort sentences by number of tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences, static_embeddings)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0meverything_embedded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_embeddings_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/embeddings.py\u001b[0m in \u001b[0;36m_add_embeddings_internal\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;31m# get hidden states from language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m         \u001b[0mall_hidden_states_in_lm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0;31m# take first or last hidden states from language model as word representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mget_representation\u001b[0;34m(self, strings, chars_per_chunk)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mrnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/flair/models/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, ordered_sequence_lengths)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from flair.hyperparameter.param_selection import TextClassifierParamSelector, OptimizationValue\n",
    "\n",
    "# create the parameter selector\n",
    "param_selector = TextClassifierParamSelector(\n",
    "    corpus, \n",
    "    False, \n",
    "    'resources/results', \n",
    "    'lstm',\n",
    "    max_epochs=2, # default 50\n",
    "    training_runs=3,\n",
    "    optimization_value=OptimizationValue.DEV_SCORE\n",
    ")\n",
    "\n",
    "# start the optimization\n",
    "param_selector.optimize(search_space, max_evals=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
